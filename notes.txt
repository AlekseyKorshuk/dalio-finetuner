
apt-get update && apt-get -y upgrade && apt-get install -y libopenmpi-dev && pip install mpi4py

git clone https://github.com/AlekseyKorshuk/dalio-finetuner && cd dalio-finetuner && pip install -r requirements.txt && pip install torch==1.12.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html && apt-get update && apt-get -y upgrade && apt-get install -y libopenmpi-dev && pip install mpi4py && wandb login && huggingface-cli login

deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-1.3b \
    --dataset_name AlekseyKorshuk/dalio-all-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /tmp/test-clm \
    --overwrite_output_dir \
    --num_train_epochs 3 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --learning_rate 3e-5 \
    --load_best_model_at_end \
    --hub_model_id AlekseyKorshuk/dalio-all-io-1.3b-3-epoch \
    --lr_scheduler_type cosine \
    --push_to_hub

&& deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-1.3b \
    --dataset_name AlekseyKorshuk/dalio-synthetic-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /tmp/test-clm \
    --overwrite_output_dir \
    --num_train_epochs 1 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 8 \
    --learning_rate 3e-5 \
    --push_to_hub \
    --load_best_model_at_end \
    --hub_model_id AlekseyKorshuk/dalio-synthetic-io-1.3b \
&& deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-1.3b \
    --dataset_name AlekseyKorshuk/dalio-all-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /tmp/test-clm \
    --overwrite_output_dir \
    --num_train_epochs 1 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 8 \
    --learning_rate 3e-5 \
    --push_to_hub \
    --load_best_model_at_end \
    --hub_model_id AlekseyKorshuk/dalio-all-io-1.3b




deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-1.3b \
    --dataset_name AlekseyKorshuk/dalio-handwritten-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /models/1.3b-handwritten-v1 \
    --overwrite_output_dir \
    --num_train_epochs 1 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 3e-5 \
    --load_best_model_at_end \
    --lr_scheduler_type cosine



deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-30b \
    --dataset_name AlekseyKorshuk/dalio-handwritten-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /models/30b-handwritten-v1 \
    --overwrite_output_dir \
    --num_train_epochs 3 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 3e-5 \
    --load_best_model_at_end \
    --lr_scheduler_type cosine \
&& deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-30b \
    --dataset_name AlekseyKorshuk/dalio-synthetic-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /models/30b-synthetic-v1 \
    --overwrite_output_dir \
    --num_train_epochs 1 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 3e-5 \
    --load_best_model_at_end \
    --lr_scheduler_type cosine \
&& deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-30b \
    --dataset_name AlekseyKorshuk/dalio-all-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /models/30b-all-2-epoch-v1 \
    --overwrite_output_dir \
    --num_train_epochs 2 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 3e-5 \
    --load_best_model_at_end \
    --lr_scheduler_type cosine \
&& deepspeed run_clm_trainer.py \
    --model_name_or_path facebook/opt-30b \
    --dataset_name AlekseyKorshuk/dalio-all-io \
    --do_train \
    --do_eval \
    --logging_strategy steps \
    --logging_steps 1 \
    --evaluation_strategy steps \
    --eval_steps 1 \
    --logging_first_step \
    --report_to all \
    --output_dir /models/30b-all-3-epoch-v1 \
    --overwrite_output_dir \
    --num_train_epochs 3 \
    --fp16 \
    --deepspeed ds_config.json \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 3e-5 \
    --load_best_model_at_end \
    --lr_scheduler_type cosine